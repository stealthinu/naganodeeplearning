# 長野ディープラーニングハンズオン準備勉強会　第1回

## ディープラーニングの応用例
- 画風変換  
https://www.youtube.com/watch?v=Khuj4ASldmU  
- カーネギー大　目の見えない人用

## 機械学習とニューラルネットワーク
- ディープラーニングとはニューラルネットワークの一種
- ニューラルネットワークは機械学習のひとつ  
他の機械学習手法  
    - 線形回帰
    - SVM
    - ベイズ推定
- 機械学習は「演繹的」に答を出すのではなく「帰納的」に法則を見つけ出す  
※図がいる、エキスパートシステムとの対比

## ニューロンとは
- ニューロン模式図
- ヘッブの学習則  
「ニューロンの発火により繋がったニューロンが発火すると結合が強化される」  
ヘッブ則そのままだと無限に重さが増えてしまうとかがありうる。弱める学習則が定義されてないので。
ヘッブ則を「ニューロン間の発火に応じて結合の強さを変更して学習する」とおおまかにとらえておけばよい。

## 形式ニューロン
- 形式ニューロン
    - w：重みづけ（実数）
    - x：入力信号（0 または 1）
    - h：しきい値（実数）
    - H：活性化関（出力は 0 または 1）
    - y：出力信号（0 または 1）
    - y=H(∑wixi−h)
- 出力方法

## 学習方法
- 出力と教師信号の差分を出す
- 差分を入力の大きさに応じて重みに足す
- つまり誤差をその責任に応じて重みを修正する

## 「マッチ箱の脳」を演習
- 手で計算
- 用紙を配る
- 最初の２、３回はみんなで一緒にやる
- 終わったらみんなで検算する
※パラメータが１つで個数を変更するモデルでやる
※単にグラフの傾きを修正してるにすぎないことが理解出来る
※パラメータが２つで個数を変更し超平面の意識をもたす
※線形分離しか出来ないことを説明



## ディープラーニングの応用例
- AlphaGo  
「アルファ碁はたくさん手を読んでいるのではなく、猛烈に勘がいい」  
https://cakes.mu/posts/12686
- 画風変換  
https://www.youtube.com/watch?v=Khuj4ASldmU  
https://play.google.com/store/apps/details?id=com.neuralprisma&hl=ja  
- 3D画像化  
https://github.com/piiswrong/deep3d
- 音声合成  
https://deepmind.com/blog/wavenet-generative-model-raw-audio/
- Kerasのデモ  
https://transcranial.github.io/keras-js/

## 機械学習とニューラルネットワーク
- ディープラーニングとはニューラルネットワークの一種
- ニューラルネットワークとは機械学習のひとつ
- 機械学習は「演繹的」に答を出すのではなく「帰納的」に法則を見つけ出す

## 形式ニューロン
- ヘッブの学習則  
ニューロンの発火により繋がったニューロンが発火すると、結合が強化される
- 形式ニューロン
    - w：重みづけ（実数）
    - x：入力信号（0 または 1）
    - h：しきい値（実数）
    - H：活性化関（出力は 0 または 1）
    - y：出力信号（0 または 1）
    - y=H(∑wixi−h)

## パーセプトロン
- パーセプトロンで1960年代に第1次ニューラルネットブームが起こる
- ミンスキーとパパートがパーセプトロンではXORの学習が出来ないことを指摘
- 小脳パーセプトロン説

## 活性化関数
- 0/1
- シグモイド関数(1/(1+e^-x) x=0でy=0.5を通る)
- tanh(x)
- ReLU

## 数式の読み方

http://s0sem0y.hatenablog.com/entry/2016/10/02/035044

入力ベクトルx=(x1,x2,...,xn)Tに対して  
y(x)=f(∑wixi+w0)  
という数式が現れます。この数式を大抵の本は以下のように変形します。  
y(x)=f(∑wixi)  
x0=1  
最初の式と、この式が全く同じ計算式  
x0=1というダミー変数を使って式を簡略化している  
x=(1,x1,x2,...,xn)とw=(w0,w1,w2,...,wn)と置き  
y(x)=f(wTx)  
この数式も最初の数式と全く同じ

１．入力データxjとそのラベルtjをセットで選びます。  
２．入力データxjに対して現在の重みwを用いて出力yを計算します。  
y(x)=f(wTxj)  
３．出力yの結果に応じてwを更新します。  
if 判定が正しかった場合  
w←w(なにも変更しない)  
else（判定が正しくない場合）  
w←w−ε∇wE(w)  
