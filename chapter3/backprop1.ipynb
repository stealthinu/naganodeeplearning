{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1** 誤差関数と勾配降下法の考えを導入しアナログ値対応します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2** 元のパーセプトロンのソースを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def h(x):\n",
    "    if x > 0.0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_perceptron(w, x):\n",
    "    # s = np.sum(w*x)\n",
    "    s = 0.0\n",
    "    for i in range(len(w)):\n",
    "        s += w[i] * x[i]\n",
    "    y = h(s - b)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_perceptron(w, x, t):\n",
    "    y = output_perceptron(w, x)\n",
    "    for i in range(len(w)):\n",
    "        dw = alpha*(t - y)*x[i]\n",
    "        w[i] += dw\n",
    "    square_error = np.square(t - y)\n",
    "    return square_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_layer(neurons_w, data, teacher):\n",
    "    square_error = 0.0\n",
    "    for i in range(len(neurons_w)):\n",
    "        square_error += train_perceptron(neurons_w[i], data, teacher[i])\n",
    "    return square_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_mnist(train_count):\n",
    "    images, labels = mnist.train.next_batch(train_count)\n",
    "    square_error = 0.0\n",
    "    for i in range(len(images)):\n",
    "        x = images[i]\n",
    "        t = labels[i]\n",
    "        square_error += train_layer(neurons_w, x, t)\n",
    "    print(square_error/train_count/10) # 1ニューロンあたりの誤差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neurons_w = np.random.rand(10, 28*28) * 0.1\n",
    "b = 0.1\n",
    "alpha = 0.01\n",
    "train_mnist(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_mnist():\n",
    "    images, labels = mnist.test.next_batch(1)\n",
    "    x = images[0]\n",
    "    t = labels[0]\n",
    "    y = np.zeros(10)\n",
    "    for i in range(len(neurons_w)):\n",
    "        y[i] = output_perceptron(neurons_w[i], x)\n",
    "    print(t)\n",
    "    print(y)\n",
    "    print(np.argmax(y))\n",
    "    # イメージ表示\n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "    plt.imshow(x.reshape((28,28)), vmin=0, vmax=1,cmap=plt.cm.gray_r, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_mnist_error():\n",
    "    test_count = 1000\n",
    "    images, labels = mnist.test.next_batch(test_count)\n",
    "    ng = 0\n",
    "    for j in range(len(images)):\n",
    "        x = images[j]\n",
    "        t = labels[j]\n",
    "        y = np.zeros(10)\n",
    "        for i in range(len(neurons_w)):\n",
    "            y[i] = output_perceptron(neurons_w[i], x)\n",
    "        if np.argmax(t) != np.argmax(y):\n",
    "            ng += 1\n",
    "    print(ng / test_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3** 活性化関数、出力の式、学習の式を修正します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.1** シグモイド関数を作ってグラフを表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = sigmoid(x)\n",
    "plt.plot(x, y)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dsigmoid(x):\n",
    "    return x*(1 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.2** 活性化関数と学習式の変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def h(x):\n",
    "    return sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dh(x):\n",
    "    return dsigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**写経** シグモイド関数とシグモイド関数の微分、活性化関数と活性化関数の微分のコードを書きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' 元のパーセプトロンの内容\n",
    "def output_perceptron(w, x):\n",
    "    s = 0.0\n",
    "    for i in range(len(w)):\n",
    "        s += w[i] * x[i]\n",
    "    y = h(s - b)\n",
    "    return y\n",
    "'''\n",
    "def output_perceptron(w, x):\n",
    "    s = np.sum(w*x)\n",
    "    y = h(s - b)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**写経** 修正したコードを写経してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' 元のパーセプトロンの内容\n",
    "def train_perceptron(w, x, t):\n",
    "    y = output_perceptron(w, x)\n",
    "    for i in range(len(w)):\n",
    "        dw = alpha*(t - y)*x[i]\n",
    "        w[i] += dw\n",
    "    square_error = np.square(t - y)\n",
    "    return square_error\n",
    "'''\n",
    "def train_perceptron(w, x, t):\n",
    "    o = output_perceptron(w, x)\n",
    "    delta = alpha*(t - o)*dh(o);\n",
    "    w += delta*x\n",
    "    square_error = np.square(t - o)\n",
    "    return square_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**写経** 修正したコードを写経してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neurons_w = np.random.rand(10, 28*28) * 0.1\n",
    "b = 0.1\n",
    "alpha = 0.01\n",
    "train_mnist(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_mnist(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_mnist(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "train_mnist(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_mnist_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
